{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from hmmaudio.features import extract_features\n",
    "from hmmaudio.hmm import HiddenMarkovModel\n",
    "from hmmaudio.utils import load_data, load_all_data, predict_label, train_hmm\n",
    "from hmmaudio.eval import evaluate_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMMAudio Demo\n",
    "\n",
    "This notebook demonstrates how to train and evaluate Hidden Markov Models for audio emotion classification using diagonal covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Happy: 100%|██████████| 1271/1271 [00:05<00:00, 238.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: Loaded 1271 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sad: 100%|██████████| 1271/1271 [00:05<00:00, 223.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad: Loaded 1271 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fear: 100%|██████████| 1271/1271 [00:05<00:00, 233.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear: Loaded 1271 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Neutral: 100%|██████████| 1087/1087 [00:04<00:00, 240.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: Loaded 1087 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Anger: 100%|██████████| 1271/1271 [00:05<00:00, 224.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: Loaded 1271 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Disgust: 100%|██████████| 1271/1271 [00:05<00:00, 213.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disgust: Loaded 1271 files\n",
      "\n",
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Happy:   0%|          | 0/48 [00:00<?, ?it/s]/Users/xgao/Documents/GitHub/HMMAudio/hmmaudio/features.py:25: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, audio = wavfile.read(file_path)\n",
      "Processing Happy: 100%|██████████| 48/48 [00:00<00:00, 119.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sad: 100%|██████████| 48/48 [00:00<00:00, 138.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fear: 100%|██████████| 48/48 [00:00<00:00, 139.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Neutral: 100%|██████████| 48/48 [00:00<00:00, 124.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Anger: 100%|██████████| 48/48 [00:00<00:00, 131.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Disgust: 100%|██████████| 48/48 [00:00<00:00, 124.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disgust: Loaded 48 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "TRAIN_DATA_PATH = \"data/data\"\n",
    "TEST_DATA_PATH = \"data/test_data\"\n",
    "\n",
    "# Load training and test data\n",
    "print(\"Loading training data...\")\n",
    "train_features, train_files = load_all_data(TRAIN_DATA_PATH,                  \n",
    "                include_mfcc=True,\n",
    "                include_delta=True,\n",
    "                include_delta2=True,\n",
    "                num_cepstral=13)\n",
    "print(\"\\nLoading test data...\")\n",
    "test_features, test_files = load_all_data(TEST_DATA_PATH,                \n",
    "                include_mfcc=True,\n",
    "                include_delta=True,\n",
    "                include_delta2=True,\n",
    "                num_cepstral=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Continuous HMMs with Diagonal Covariance\n",
    "\n",
    "We'll use diagonal covariance matrices instead of full covariance matrices for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [07:09<00:00, 42.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [07:48<00:00, 46.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Fear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [07:39<00:00, 45.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [06:10<00:00, 37.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Anger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [07:46<00:00, 46.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for Disgust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baum-Welch Training Progress: 100%|██████████| 10/10 [08:16<00:00, 49.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set HMM parameters\n",
    "n_states = 5 \n",
    "n_features = train_features[\"Anger\"][0].shape[1]  # Number of features\n",
    "max_iter = 10  # Number of Baum-Welch iterations\n",
    "\n",
    "# Train HMMs with diagonal covariance (faster)\n",
    "hmm_models = train_hmm(\n",
    "    train_features, \n",
    "    n_states=n_states, \n",
    "    n_symbols=n_features,\n",
    "    max_iter=max_iter,\n",
    "    continuous = True,  # Use continuous HMM\n",
    "    diagonal_covariance=True,  # Use diagonal covariance for speed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "\n",
    "Now we'll evaluate the trained HMM models on both the training and test sets.\n",
    "We'll use the new score method to calculate the log-likelihood of each sequence and normalize by sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Happy: 100%|██████████| 1271/1271 [01:30<00:00, 14.07it/s]\n",
      "Evaluating Sad: 100%|██████████| 1271/1271 [01:40<00:00, 12.61it/s]\n",
      "Evaluating Fear: 100%|██████████| 1271/1271 [01:37<00:00, 13.01it/s]\n",
      "Evaluating Neutral: 100%|██████████| 1087/1087 [01:21<00:00, 13.34it/s]\n",
      "Evaluating Anger: 100%|██████████| 1271/1271 [01:40<00:00, 12.67it/s]\n",
      "Evaluating Disgust: 100%|██████████| 1271/1271 [01:47<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.39\n",
      "Train Confusion Matrix:\n",
      "[[386 121 180  62 324 198]\n",
      " [ 47 768 103 137  25 191]\n",
      " [173 381 271  49 258 139]\n",
      " [138 262 130 230  41 286]\n",
      " [234  16  39   1 892  89]\n",
      " [187 303 158  86 190 347]]\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Happy: 100%|██████████| 48/48 [00:05<00:00,  9.37it/s]\n",
      "Evaluating Sad: 100%|██████████| 48/48 [00:05<00:00,  9.07it/s]\n",
      "Evaluating Fear: 100%|██████████| 48/48 [00:05<00:00,  9.33it/s]\n",
      "Evaluating Neutral: 100%|██████████| 48/48 [00:05<00:00,  9.35it/s]\n",
      "Evaluating Anger: 100%|██████████| 48/48 [00:05<00:00,  8.68it/s]\n",
      "Evaluating Disgust: 100%|██████████| 48/48 [00:05<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.20\n",
      "Test Confusion Matrix:\n",
      "[[ 3  8 22  0 14  1]\n",
      " [ 1 14 16  0 15  2]\n",
      " [ 5  5 25  0 11  2]\n",
      " [ 2 13 20  0 13  0]\n",
      " [11  3 17  0 15  2]\n",
      " [ 6  5 22  0 15  0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "print(\"\\nEvaluating on training set...\")\n",
    "train_accuracy, train_cm, _, _, _ = evaluate_models(\n",
    "    hmm_models, \n",
    "    train_features, \n",
    "    train_files,\n",
    "    normalize_by_length=True  # Normalize by sequence length to handle variable-length audio\n",
    ")\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(train_cm)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_accuracy, test_cm, _, _, _ = evaluate_models(\n",
    "    hmm_models, \n",
    "    test_features, \n",
    "    test_files,\n",
    "    normalize_by_length=True\n",
    ")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Classify a Single Audio Sample\n",
    "\n",
    "Let's test the model on a single audio sample and print the scores for each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotion: Anger\n",
      "Predicted emotion: Fear\n",
      "\n",
      "Scores for each emotion (log-likelihood/frame, higher is better):\n",
      "Fear:     0.54\n",
      "Happy:    -0.25\n",
      "Sad:    -0.40\n",
      "Disgust:    -0.59\n",
      "Neutral:    -1.08\n",
      "Anger:    -1.79\n"
     ]
    }
   ],
   "source": [
    "# Choose a sample from the test set\n",
    "true_emotion = \"Anger\"\n",
    "sample_index = 10  # Choose any sample index\n",
    "sample_features = test_features[true_emotion][sample_index]\n",
    "\n",
    "# Predict using utility function\n",
    "predicted_emotion, scores = predict_label(hmm_models, sample_features)\n",
    "\n",
    "# Print results\n",
    "print(f\"True emotion: {true_emotion}\")\n",
    "print(f\"Predicted emotion: {predicted_emotion}\")\n",
    "print(\"\\nScores for each emotion (log-likelihood/frame, higher is better):\")\n",
    "\n",
    "# Normalize scores by sequence length for fair comparison\n",
    "normalized_scores = {emotion: score/len(sample_features) for emotion, score in scores.items()}\n",
    "\n",
    "# Sort and print scores from highest to lowest\n",
    "for emotion, score in sorted(normalized_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{emotion}: {score:8.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc413",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
